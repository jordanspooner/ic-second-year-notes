\documentclass[twocolumn,english]{article}
\usepackage[latin9]{inputenc}
\usepackage[landscape]{geometry}
\geometry{verbose,tmargin=0.5in,bmargin=0.75in,lmargin=0.5in,rmargin=0.5in}
\setlength{\parskip}{0bp}
\setlength{\parindent}{0pt}
\usepackage{array}
\usepackage{float}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}

\makeatletter

\providecommand{\tabularnewline}{\\}




\usepackage{array}
\usepackage{multirow}
\usepackage{amsbsy}




\providecommand{\tabularnewline}{\\}

\setlength{\columnsep}{0.25in}
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{listings}
\lstset{
  tabsize=2,
  basicstyle=\small\ttfamily,
}



\usepackage{babel}
\usepackage{listings}
\renewcommand{\lstlistingname}{Listing}

\makeatother

\usepackage{babel}
\begin{document}

\title{Reference Sheet for CO231 Artificial Intelligence}

\date{Autumn 2017}
\maketitle

\section{Search}

\paragraph{Requirements}
\begin{enumerate}
\item \emph{Observable}: current state is known.
\item \emph{Discrete}: finitely many next states from each state.
\item \emph{Deterministic}: each action has exactly one outcome.
\item \emph{Known}: possible actions and next states known.
\end{enumerate}

\paragraph{Formal Definition}
\begin{enumerate}
\item Initial state (\emph{start}).
\item Transition model between states (\emph{graph}).
\item Goal tests (set of \emph{goal} states).
\item Path cost (sum of positive step costs).
\end{enumerate}
\rule[0.5ex]{0.25\columnwidth}{0.5pt}
\begin{enumerate}
\item Solution is \emph{path} from initial state to a goal state.
\item Optimal solution has lowest cost.
\end{enumerate}

\paragraph{Algorithms}

Generate a search tree:
\begin{enumerate}
\item Initialise the tree with initial state as root.
\item Repeat:
\begin{enumerate}
\item If frontier of tree is empty then fail.
\item Choose and remove leaf node $L$ from frontier.
\item If $L$ is a goal state, then return solution.
\item Add $L$ to seen states.
\item Expand $L$ (if not seen), adding resulting nodes to frontier.
\end{enumerate}
\end{enumerate}
To add \emph{loop checking}, each seen $L$ is added to an explored
set and only expanded if not already seen.

\subsection{Uninformed / Blind Search}

Choose next unexpanded node using:
\begin{enumerate}
\item \emph{Breadth first search}: choose shallowest node.
\item \emph{Uniform cost search}: choose node with lowest path cost.
\item \emph{Depth first search}: choose deepest node.
\item \emph{Depth limited search}: DFS with depth limit $l$.
\item \emph{Iterative deepening search}: depth limited search with increasing
$l$.
\end{enumerate}

\paragraph{Variants}
\begin{enumerate}
\item \emph{Backtracking search}: only generate one node when expanded,
remember what to generate next.
\item \emph{Bi-directional search}: Two simultaneous searches from start
to goal and goal to start.
\end{enumerate}

\paragraph{Properties}
\begin{enumerate}
\item \emph{Completeness:} do we always find a solution if one exists?
\item \emph{Time complexity}: number of nodes expanded.
\item \emph{Space complexity}: max number of nodes in memory.
\item \emph{Optimality}: do we always find the least-cost solution?
\end{enumerate}
\begin{table}[H]
\centering{}%
\begin{tabular}{>{\centering}m{0.12\columnwidth}>{\centering}m{0.18\columnwidth}>{\centering}m{0.18\columnwidth}>{\centering}m{0.18\columnwidth}>{\centering}m{0.18\columnwidth}}
\toprule 
 & \textbf{\footnotesize{}Completeness} & \textbf{\footnotesize{}Time Complexity} & \textbf{\footnotesize{}Space Complexity} & \textbf{\footnotesize{}Optimality}\tabularnewline
\midrule
\emph{\footnotesize{}BFS} & {\footnotesize{}Yes if $b$ is finite} & {\footnotesize{}$O\left(b^{d}\right)$} & {\footnotesize{}$O\left(b^{d}\right)$} & {\footnotesize{}Yes if costs are constant}\tabularnewline
\addlinespace[0.25cm]
\emph{\footnotesize{}Uniform-cost} & {\footnotesize{}Yes if $b$ is finite and all costs are positive} & {\footnotesize{}$O\left(b^{d+1}\right)$ if costs are constant} & {\footnotesize{}$O\left(b^{d+1}\right)$ if costs are constant} & {\footnotesize{}Yes}\tabularnewline
\addlinespace[0.25cm]
\emph{\footnotesize{}DFS} & {\footnotesize{}Yes if $s$ is finite}\\
{\scriptsize{}(No without loop checking)} & {\footnotesize{}$s$}\\
{\scriptsize{}($O(b^{m})$ without loop checking)} & {\footnotesize{}$O\left(bm\right)$} & {\footnotesize{}No}\tabularnewline
\addlinespace[0.25cm]
\emph{\footnotesize{}Back-tracking DFS} & \multicolumn{4}{c}{{\footnotesize{}As for DFS but with $O\left(m\right)$ space complexity.}}\tabularnewline
\addlinespace[0.25cm]
\emph{\footnotesize{}Depth-limited DFS} & {\footnotesize{}No} & {\footnotesize{}$s\left(l\right)$}\\
{\scriptsize{}($O(b^{l})$ without loop checking)} & {\footnotesize{}$O\left(bl\right)$} & {\footnotesize{}No}\tabularnewline
\addlinespace[0.25cm]
\emph{\footnotesize{}Iterative deepening DFS} & \multicolumn{4}{c}{{\footnotesize{}As for BFS but with $O\left(bd\right)$ space complexity.}}\tabularnewline
\addlinespace[0.25cm]
\emph{\footnotesize{}Bidirectional BFS} & \multicolumn{4}{c}{{\footnotesize{}As for BFS but with $O\left(b^{d/2}\right)$ time
and space complexity.}}\tabularnewline
\bottomrule
\addlinespace[0.25cm]
\end{tabular}
\end{table}

Where:
\begin{itemize}
\item $b$ is the maximum branching factor of the search tree.
\item $d$ is the depth of the optimal solution.
\item $m$ is the max depth of the state space.
\item $s$ is the overall size of the state space.
\item $s\left(l\right)$ is the size of the state space up to depth $l$.
\end{itemize}

\subsection{Informed / Heuristic-Based Search}

Use a cost estimate to choose node with least-estimated path cost.
\begin{enumerate}
\item \emph{Greedy-best-first-search}: $\text{cost estimate}=\text{heuristic on this node}$.
\item \emph{A{*} search}: $\text{cost estimate}=\text{actual cost to node}+\text{heuristic on this node}$.
\item \emph{Local search}: e.g. genetic algorithms, simulated annealing.
\end{enumerate}

\paragraph{Heuristic Functions}

Required properties (where $g\left(n,m\right)$ is the actual cost
of reaching $m$ from $n$ and $h\left(n\right)$ is the heuristic
function applied to $n$):
\begin{enumerate}
\item \emph{Consistent} / \emph{Monotonic}: $h\left(n\right)\leq g\left(n,n'\right)+h\left(n'\right)$
for any $n'$ successor of $n$. (Doesn't overestimate actual cost
to any successor + heuristic applied to that node).
\item \emph{Admissible} (follows from consistency): $h\left(n\right)\leq g\left(n,m_{goal}\right)$
where $m_{goal}$ is the cheapest reachable goal from $n$. (Doesn't
overestimate actual cost to goal).
\end{enumerate}
\begin{itemize}
\item Often admissible / consistent heuristics come from a relaxed version
of the search problem (more edges).
\end{itemize}

\paragraph{Properties}

\begin{table}[H]
\centering{}%
\begin{tabular}{>{\centering}m{0.25\columnwidth}>{\centering}m{0.3\columnwidth}>{\centering}m{0.3\columnwidth}}
\toprule 
 & \textbf{\footnotesize{}Completeness} & \textbf{\footnotesize{}Optimality}\tabularnewline
\midrule
\emph{\footnotesize{}Greedy} & {\footnotesize{}Yes if $s$ is finite} & {\footnotesize{}No}\tabularnewline
\emph{\footnotesize{}Greedy (without loop checking)} & {\footnotesize{}No} & {\footnotesize{}No}\tabularnewline
\midrule
\emph{\footnotesize{}A{*}} & {\footnotesize{}Yes if $b$ is finite and all costs are positive} & {\footnotesize{}Yes if heuristic is consistent}\tabularnewline
\emph{\footnotesize{}A{*} (without loop checking)} & {\footnotesize{}Yes if $b$ is finite and all costs are positive} & {\footnotesize{}Yes if heuristic is admissible}\tabularnewline
\bottomrule
\end{tabular}
\end{table}

A{*} is optimally efficient but often runs out of space.

\subsection{Adversarial Search}

Used for:
\begin{itemize}
\item Competitive environment (opponents with conflicting goals).
\item Unpredictable opponent.
\item Hard to solve, time limits.
\end{itemize}
Definitions for two-player, zero-sum games:
\begin{itemize}
\item $s_{0}$: initial state.
\item $\texttt{PLAYER}\left(s\right)$: which player moves in a state.
\item $\texttt{ACTIONS}\left(s\right)$: set of legal moves in a state.
\item $\texttt{RESULT}\left(s,a\right)$: state resulting from move in a
state.
\item $\texttt{UTILITY}\left(s,p\right)$: win (1), lose (-1) or draw (0).
\end{itemize}
Optimal strategies for perfect-information, deterministic games:
\begin{enumerate}
\item Minimax.
\item Alpha-beta pruning.
\end{enumerate}

\paragraph{Minimax}

\texttt{}
\begin{table}[H]
\raggedright{}\texttt{\small{}if $\lnot\texttt{TERMINAL}\left(s\right)$:}~\\
\texttt{\small{}$\qquad$if $\texttt{PLAYER}\left(s\right)=\texttt{MAX}$
then return $\max_{a=\texttt{ACTIONS}\left(s\right)}\texttt{MINIMAX}\left(\texttt{RESULT}\left(s,a\right)\right)$}~\\
\texttt{\small{}$\qquad$if $\texttt{PLAYER}\left(s\right)=\texttt{MIN}$
then return $\min_{a=\texttt{ACTIONS}\left(s\right)}\texttt{MINIMAX}\left(\texttt{RESULT}\left(s,a\right)\right)$}~\\
\texttt{\small{}if $\texttt{TERMINAL}\left(s\right)$:}~\\
\texttt{\small{}$\qquad$return $\texttt{UTILITY}\left(s\right)$}
\end{table}

\paragraph{Alpha-beta pruning}
\begin{itemize}
\item $\alpha$ is the minimum value that \texttt{MAX} is guaranteed to
achieve so far (minimiser's best guaranteed score).
\item $\beta$ is the maximum value that \texttt{MAX} is a guaranteed to
achieve so far (maximiser's best guaranteed score).
\end{itemize}
Starting with $\texttt{max-value}\left(s,-\infty,\infty\right)$:

\texttt{}
\begin{table}[H]
\raggedright{}\texttt{\small{}max-value$\left(s,\alpha,\beta\right)$:}~\\
\texttt{\small{}$\qquad$if $\lnot\texttt{TERMINAL}\left(s\right)$:}~\\
\texttt{\small{}$\qquad\qquad$let $v=-\infty$}~\\
\texttt{\small{}$\qquad\qquad$for each $a$ in $\texttt{ACTIONS}\left(s\right)$:}~\\
\texttt{\small{}$\qquad\qquad\qquad$let $v=\max\left(v,\texttt{min-value}\left(\texttt{RESULT}\left(s,a\right),\alpha,\beta\right)\right)$}~\\
\texttt{\small{}$\qquad\qquad\qquad$if $v\geq\beta$ then return
$v$}~\\
\texttt{\small{}$\qquad\qquad\qquad$else let $\alpha=\max\left(\alpha,v\right)$}~\\
\texttt{\small{}$\qquad\qquad$return $v$}~\\
\texttt{\small{}$\qquad$if $\texttt{TERMINAL}\left(s\right)$:}~\\
\texttt{\small{}$\qquad\qquad$return $\texttt{UTILITY}\left(s\right)$}
\end{table}
\texttt{}
\begin{table}[H]
\raggedright{}\texttt{\small{}min-value$\left(s,\alpha,\beta\right)$:}~\\
\texttt{\small{}$\qquad$if $\lnot\texttt{TERMINAL}\left(s\right)$:}~\\
\texttt{\small{}$\qquad\qquad$let $v=\infty$}~\\
\texttt{\small{}$\qquad\qquad$for each $a$ in $\texttt{ACTIONS}\left(s\right)$:}~\\
\texttt{\small{}$\qquad\qquad\qquad$let $v=\min\left(v,\texttt{max-value}\left(\texttt{RESULT}\left(s,a\right),\alpha,\beta\right)\right)$}~\\
\texttt{\small{}$\qquad\qquad\qquad$if $v\leq\alpha$ then return
$v$}~\\
\texttt{\small{}$\qquad\qquad\qquad$else let $\beta=\min\left(\beta,v\right)$}~\\
\texttt{\small{}$\qquad\qquad$return $v$}~\\
\texttt{\small{}$\qquad$if $\texttt{TERMINAL}\left(s\right)$:}~\\
\texttt{\small{}$\qquad\qquad$return $\texttt{UTILITY}\left(s\right)$}
\end{table}
\begin{itemize}
\item \emph{Key idea}: If this move ever gives the opponent a choice to
do better than the best they could do in a different move, then we
shouldn't consider it.
\end{itemize}

\paragraph{Properties}

\begin{table}[H]
\centering{}%
\begin{tabular}{>{\centering}m{0.12\columnwidth}>{\centering}m{0.18\columnwidth}>{\centering}m{0.18\columnwidth}>{\centering}m{0.18\columnwidth}>{\centering}m{0.18\columnwidth}}
\toprule 
 & \textbf{\footnotesize{}Completeness} & \textbf{\footnotesize{}Time Complexity} & \textbf{\footnotesize{}Space Complexity} & \textbf{\footnotesize{}Optimality}\tabularnewline
\midrule
\emph{\footnotesize{}Minimax} & {\footnotesize{}Yes if search tree is finite} & {\footnotesize{}$O\left(b^{m}\right)$} & {\footnotesize{}$O\left(bm\right)$} & {\footnotesize{}Yes}\tabularnewline
\addlinespace[0.25cm]
\emph{\footnotesize{}$a$-$\beta$ pruning} & \multicolumn{4}{c}{{\footnotesize{}As for minimax but with $O\left(b^{m/2}\right)$ time
complexity.}}\tabularnewline
\bottomrule
\addlinespace[0.25cm]
\end{tabular}
\end{table}

\paragraph{Limited Resources}
\begin{itemize}
\item Cutoff-test instead of \texttt{TERMINAL}.
\item Evaluation instead of \texttt{UTILITY}.
\end{itemize}

\section{Planning}

\paragraph{Requirements}

Observable, discrete, deterministic, known.

\paragraph{STRIPS Language for Planning}
\begin{enumerate}
\item \emph{States} - conjunctions of ground atoms.
\item \emph{Goals} - conjunctions of literals - possibly containing variables
- implicitly existentially quantified.
\item \emph{Operators}:
\begin{enumerate}
\item Action description.
\item \emph{Precondition} - conjunction of literals.
\item \emph{Postcondition} (\emph{Effect}) - conjunction of literals. Every
variable in effect must appear in pre-condition.
\end{enumerate}
\item \emph{Actions} - fully instantiated operators.
\end{enumerate}
\[
\text{Precondition}\xrightarrow{\text{Action}}\text{Postcondition}
\]

\paragraph{Execution of an Action}

New State = Current state - negation of negative fluents in effects
+ positive fluents in effects

\paragraph{Assumptions}
\begin{itemize}
\item Fluents not mentioned in a state are false.
\item Fluents do not change unless they are explicitly changed by an action.
\item Time is implicit.
\end{itemize}

\subsection{Planning as Search}
\begin{enumerate}
\item \emph{Progression planning} (forward) - blind search with the graph
obtained from the specification of the planning problem.
\begin{enumerate}
\item \emph{Problem}: Large search spaces with many irrelevant actions.
\item \emph{Solution}: Good heuristics; relax the problem, add extra edges
e.g. by ignoring preconditions and effects not in goal.
\end{enumerate}
\item \emph{Regression planning} (backward) - blind search backwards from
the goal.
\begin{enumerate}
\item \emph{Problem}: Non-interleaved regression planning is incomplete
\end{enumerate}
\end{enumerate}

\subsection{Graph-Plan Algorithm}

\begin{figure}[H]
\centering{}\includegraphics[width=0.9\columnwidth]{img/graph-plan}
\end{figure}
\begin{itemize}
\item \emph{Level $S_{i}$}:
\begin{itemize}
\item $i=0$: Start state + literals that could hold at the start.
\item $i>0$: all literals that could hold at $S_{i}$, depending on actions
at $A_{i-1}$.
\end{itemize}
\item \emph{Level $A_{i}$}:
\begin{itemize}
\item Each action in $A_{i}$ connected to its precondition in $S_{i}$
and effect at $S_{i+1}$.
\item No-op actions: no change.
\end{itemize}
\item Mutual exclusions between actions when:
\begin{enumerate}
\item Actions have \emph{inconsistent effects}.
\item \emph{Interference}: effect of one action = $\lnot$ precondition
of the other.
\item \emph{Competing needs}: mutually exclusive pre-conditions.
\end{enumerate}
\item Mutual exclusions between literals when:
\begin{enumerate}
\item They are \emph{complementary}.
\item \emph{Inconsistent support}: Each possible pair of actions achieving
them are mutex.
\end{enumerate}
\item Levels off: when two consecutive levels are identical.
\end{itemize}

\paragraph{Extracting the Plan}

Once goal is non-mutex in $S_{i}$, search backwards to extract plan.

\section{Knowledge Representation and Automated Reasoning}
\begin{enumerate}
\item Find a representation for the problem.
\item Compute output using automatic reasoning.
\item Output mapped into solution to the problem.
\end{enumerate}

\paragraph{Clausal Form}

Resolution works with conjunctions of clauses:
\[
\lnot p_{1}\lor\dots\lor\lnot p_{m}\lor q_{1}\lor\dots\lor q_{n}
\]

where each $p_{i}$ and $q_{j}$ is an atom.
\begin{itemize}
\item If $m=n=0$: called the empty clause ($\square$).
\item Every clause can be written as an implication $p_{1}\land\dots\land p_{m}\rightarrow q_{1}\lor\dots\lor q_{n}$.
\item Every propositional logic formula can be written as a conjunction
of clauses (conjunctive normal form).
\item Every first-order logic sentence can be written as a conjunction of
clauses (universal qualification + conjunctive normal form + Skolemisation).
\end{itemize}

\subsection{Unification}

\paragraph{Universal Instantiation}

Combines two clauses:
\[
\dfrac{\forall v\alpha}{\alpha\left\{ v/g\right\} }
\]
for any variable $v$ and term $g$.
\begin{itemize}
\item $\sigma=\left\{ v/g\right\} $ is a \emph{substitution}. $\alpha\sigma$
means the formula obtained from $\alpha$ by applying $\sigma$.
\end{itemize}

\paragraph{Unification}

A substitution $\sigma$ unifies atomic sentences $p$ and $q$ if
$p\sigma=q\sigma$.
\begin{itemize}
\item E.g. $p=\text{Knows}\left(\text{John},x\right)$, $\text{Knows}\left(y,\text{OJ}\right)$,
$\sigma=\left\{ x/\text{OJ},y/\text{John}\right\} $.
\end{itemize}

\paragraph{Most General Unifier}

$\theta$ is a most general unifier of formulas $\alpha$ and $\beta$
if:
\begin{enumerate}
\item $\theta$ unifies formulas $\alpha$ and $\beta$.
\item If $\sigma$ is any other unifier of $\alpha$ and $\beta$, then
$\alpha\sigma$ is an instance of $\alpha\theta$ (i.e. $\alpha\sigma=\left(\alpha\theta\right)\sigma'$
for some $\sigma'$).
\end{enumerate}

\subsection{Resolution}

\subsubsection{Propositional Logic}

\paragraph{Resolution Inference Rule}

Combines two clauses:
\[
\dfrac{\alpha\lor\beta,\lnot\beta\lor\gamma}{\alpha\lor\gamma}
\]

Applied repeatedly until $\square$ is derived.

\paragraph{Completeness of Resolution}
\begin{itemize}
\item If conjunction of propositional clauses is unjustifiable, we will
end up with $\square$.
\item To prove a goal $P$ is entailed by a set of sentences $S$ ($S\vDash P$):
\begin{enumerate}
\item Compute CNF of $S$ and $\lnot P$.
\item Apply resolution to results of step 1 to obtain $\square$.
\end{enumerate}
\end{itemize}

\subsubsection{First-Order Logic}

\paragraph{Resolution Inference Rule}

\[
\dfrac{\alpha\lor\beta,\lnot\beta'\lor\gamma}{\left(\alpha\lor\gamma\right)\theta}\text{ where \ensuremath{\theta} is a mgu of \ensuremath{\beta} and \ensuremath{\beta'}}
\]

Full version:
\[
\dfrac{\alpha^{1}\lor\dots\lor a^{j-1}\lor a^{j}\lor a^{j+1}\lor\dots\lor\alpha^{m},\beta^{1}\lor\dots\lor\beta^{k-1}\lor\beta^{k}\lor\beta^{k+1}\lor\dots\lor\beta^{n}}{\left(\alpha^{1}\lor\dots\lor a^{j-1}\lor a^{j+1}\lor\dots\lor\alpha^{m},\beta^{1}\lor\dots\lor\beta^{k-1}\lor\beta^{k+1}\lor\dots\lor\beta^{n}\right)\theta}
\]
where $\theta$ is a mgu of $\alpha^{j}$ and $\lnot\beta^{k}$.

\subsection{GMP / SLD Resolution}

\paragraph{Definite Clauses}

Clauses of the form (for atoms $p,q_{1},\dots,q_{n}$)
\[
p\leftarrow q_{1},q_{2},\dots,q_{n}
\]
\begin{itemize}
\item $p$ is the \emph{head} and $q_{1},\dots,q_{n}$ the \emph{body} of
the clause.
\item If $n=0$, $p$ is a \emph{fact}.
\item A set of definite clauses is a \emph{logic program}.
\item A \emph{Horn clause} is a definite clause or $\leftarrow q_{1},\dots,q_{n}$.
\end{itemize}

\paragraph{Generalised Modus Ponens
\[
\dfrac{p'_{1},p'_{2},\dots,p'_{n},\left(q\leftarrow p_{1},p_{2},\dots,p_{n}\right)}{q\theta}
\]
}

where $p'_{i}\theta=p_{i}\theta$.

\paragraph{SLD Resolution}

\[
\dfrac{\overbrace{\lnot\alpha^{1}\lor\dots\lor\lnot\alpha^{j}\lor\dots\lor\lnot\alpha^{m}}^{\text{Goal}},\overbrace{\alpha\lor\lnot\beta^{1}\lor\dots\lor\lnot\beta^{n}}^{\text{Definite Clause}}}{\left(\lnot\alpha^{1}\lor\dots\lor\lnot\beta^{1}\lor\dots\lor\lnot\beta^{n}\lor\dots\lor\lnot a^{m}\right)\theta}
\]
where $\theta$ is a mgu of $\alpha^{j}$ and $\alpha$.

\paragraph{Alternative View SLD Resolution}

\begin{align*}
\: & \leftarrow L_{1},\dots,L_{j-1},B,L_{j+1},\dots,L_{n}\\
\theta_{i} & \mid\text{match \ensuremath{B} with \ensuremath{B'\leftarrow M_{1},\dots,M_{k}} since \ensuremath{B\theta_{i}=B'\theta_{i}}}\\
\: & \leftarrow\left(L_{1},\dots,L_{j-1},M_{1},\dots,M_{k},L_{j+1},\dots,L_{n}\right)\theta_{i}
\end{align*}
\begin{itemize}
\item Answer is computed from composition of all mgus.
\item Sub-goal $B$ can be chosen in any way.
\item There are many choices for the matching clause.
\end{itemize}

\subsection{Forward and Backward Chaining}

To prove that $S\vDash P$:
\begin{enumerate}
\item Compute the CNF $S'$ of $S$.
\item Compute the CNF $NP'$ of $\lnot P$.
\item If $S'$ is a set of definite clauses (logic program) and $NP'$ is
a Horn clause $\leftarrow q_{1},\dots,q_{n}$, then apply GMP to derive
$q_{1},\dots,q_{n}$ from $S'$.
\end{enumerate}

\paragraph{Forward Chaining (Bottom-Up Computation)}
\begin{enumerate}
\item Split $S'$ into facts $E$ and definite clauses (rules) $Pr$.
\item Apply the rules in $Pr$ to the facts in $E$ using GMP to derive
implied facts $E'$.
\item Add $E'$ to $E$.
\item Repeat until no new facts are generated.
\item Succeed iff $q_{1},\dots,q_{n}$ are in $E$.
\end{enumerate}
Likely to produce a lot of irrelevant facts.

\paragraph{Backward Chaining (Top-Down / Goal-Directed Computation)}

Start with goals $q_{1},\dots,q_{n}$ and $\theta=\{\}$. To solve
a goal $G$ wrt $\theta$:
\begin{enumerate}
\item If there is a matching fact $G'$ in $S'$, add mgu $\sigma$ to $\theta$
($G\sigma=G'\sigma$).
\item For each rule $G'\leftarrow G_{1},\dots,G_{m}$ in $S'$ whose head
$G'$ matches $G$ via mgu $\sigma'$, solve goals $G_{1}\sigma',\dots,G_{m}\sigma'$
wrt to $\theta+\left\{ \sigma'\right\} $.
\item Repeat until there are no goals to solve, return $\theta$.
\end{enumerate}

\subsection{Semantics of Definite Clauses}
\begin{itemize}
\item \emph{Herbrand universe}: set of all ground terms that can be constructed
from constant and function symbols in $S$.
\item Each set of definite clauses $S$ can be can be equated to the set
of all its ground instances over the underlying Herbrand universe.
\end{itemize}

\paragraph{Classical Models}

Interpretations of $S$:
\begin{itemize}
\item Mappings from ground terms of $S$ to elements of some domain $D$.
\end{itemize}
Models of $S$:
\begin{itemize}
\item Interpretations of $S$ in which every clause of $S$ is true.
\end{itemize}

\paragraph{Herbrand Models}

Models where ground terms denote themselves (i.e. domain is Herbrand
universe of $S$).
\begin{itemize}
\item $S$ has a model iff $S$ has a (minimal) Herbrand model.
\end{itemize}

\paragraph{Immediate Consequence Operator $T_{s}$}
\begin{itemize}
\item \emph{Herbrand Base} $HB$: Set of all ground atoms constructed from
predicate symbols in $S$ over the Herbrand universe of $S$.
\item Given $X\subseteq HB$, $T_{s}\left(X\right)=\left\{ a\in HB\mid a\leftarrow b_{1},\dots,b_{m}\in S,\left\{ b_{1},\dots,b_{m}\right\} \subseteq X\right\} $.
\item Least fixed point, given by $T_{s}\uparrow^{\omega}=\cup_{i=0}^{\infty}T_{s}\left(\emptyset\right)$,
which is the minimal Herbrand model of S.
\end{itemize}

\subsection{SLD Resolution is Complete}

If $S\vDash P\sigma$ (i.e. $P\sigma$ belongs to the minimal Herbrand
model of $S$), then there exists and SLD-refutation of $P$ to obtain
$\square$ with answer $\theta$ and a substitution of $\xi$ such
that $P\sigma=P\theta\xi$.

\subparagraph{Example}

\begin{align*}
 & S=\left\{ P\left(x,y\right)\leftarrow Q\left(x\right),Q\left(1\right)\leftarrow,R\left(2\right)\leftarrow\right\} \\
 & \leftarrow P\left(x,y\right)\\
 & \leftarrow Q\left(x\right)\\
 & \square\theta=\left\{ x/1\right\} 
\end{align*}

$P\left(1,2\right)$ belongs to the minimal Herbrand model of $S=\left\{ Q\left(1\right),R\left(2\right),P\left(1,1\right),P\left(1,2\right)\right\} $
with $\xi=\left\{ y/2\right\} $.

\section{Non-monotonic Reasoning}

\paragraph{Non-monotonic Logics}

In the absence of information to the contrary, results follow by default.

E.g.
\begin{align*}
 & \text{BIRDS}=\text{flies}\left(X\right)\leftarrow,\lnot\text{penguin}\left(X\right),\lnot\text{wounded}\left(X\right),\dots\\
 & \text{BIRDS}\cup\left\{ \text{bird}\left(\text{tweety}\right)\right\} \vDash^{*}\text{flies}\left(\text{tweety}\right)\\
 & \text{BIRDS}\cup\left\{ \text{bird}\left(\text{tweety}\right)\right\} \cup\left\{ \text{penguin}\left(\text{tweety}\right)\right\} \not\vDash^{*}\text{flies}\left(\text{tweety}\right)
\end{align*}

\paragraph{Closed World Assumption}

If $\alpha$ is not present in some $DB$, then assume $\lnot\alpha$.

\paragraph{Negation as Failure}

$\lnot B$ succeeds when all attempts to prove $B$ fail.

\paragraph{Credulous vs. Sceptical Reasoning}

Assume Quakers are pacifists and republicans are not. Nixon is a Quaker
and a Republican. Is Nixon a pacifist or not?
\begin{itemize}
\item \emph{Sceptical / cautious reasoning}: No.
\item \emph{Credulous / brave reasoning}: Yes, to both.
\end{itemize}

\subsection{SLDNF}

Derivation steps:
\begin{itemize}
\item Select any positive literal $L_{j}=B$ from the current goal:
\end{itemize}
\begin{align*}
\: & \leftarrow L_{1},\dots,L_{j-1},B,L_{j+1},\dots,L_{n}\\
\theta_{i} & \mid\text{match \ensuremath{B} with \ensuremath{B'\leftarrow M_{1},\dots,M_{k}} since \ensuremath{B\theta_{i}=B'\theta_{i}}}\\
\: & \leftarrow\left(L_{1},\dots,L_{j-1},M_{1},\dots,M_{k},L_{j+1},\dots,L_{n}\right)\theta_{i}
\end{align*}
\begin{itemize}
\item Select any (\emph{safe} / non-ground) negative literal $L_{j}=\text{not }B$
from the current goal:
\end{itemize}
\begin{align*}
\: & \leftarrow L_{1},\dots,L_{j-1},\text{not }B,L_{j+1},\dots,L_{n}\\
\theta_{i}=\{\} & \mid\text{all ways of computing goal \ensuremath{B} must fail (finitely)}\\
\: & \leftarrow\left(L_{1},\dots,L_{j-1},L_{j+1},\dots,L_{n}\right)\theta_{i}
\end{align*}

\paragraph{Properties}

Consider
\begin{align*}
 & p\left(X\right)\leftarrow q\left(X\right),\text{not }r\left(X\right)\\
 & q\left(a\right)\\
 & r\left(b\right)
\end{align*}
\begin{itemize}
\item \emph{Non-monotonic}: $S\vdash_{\text{SLDNF}}p\left(a\right)$ but
$S\cup\left\{ r\left(a\right)\right\} \not\vdash_{\text{SLDNF}}p\left(a\right)$.
\item Builds in a kind of \emph{CWA}: $S\cup\left\{ r\left(a\right)\right\} \vdash_{\text{SLDNF}}\lnot p\left(a\right)$.
\end{itemize}

\subsection{Semantics for Normal Logic Programs}

\subsubsection{Completion Semantics}

The \emph{completion} of $S$ is found by:
\begin{enumerate}
\item Rewrite all rules in $S$ as rules of the form
\[
p\left(\overrightarrow{X}\right)\leftarrow\overrightarrow{X}=\overrightarrow{t},\text{body}
\]
so $p\left(X,3\right)\leftarrow q\left(X\right),\text{not }r\left(3\right)$
becomes $p\left(X,Y\right)\leftarrow Y=3\land q\left(X\right)\land\lnot r\left(3\right)$
\item Combine all rules with the same head so 
\[
p\left(\overrightarrow{X}\right)\leftarrow\overrightarrow{X}=\overrightarrow{t}_{1},\text{body}_{1},\dots,p\left(\overrightarrow{X}\right)\leftarrow\overrightarrow{X}=\overrightarrow{t}_{n},\text{body}_{n}
\]
becomes
\[
p\left(\overrightarrow{X}\right)\leftrightarrow\overrightarrow{X}=\overrightarrow{t}_{1},\text{body}_{1}\lor\dots\lor p\left(\overrightarrow{X}\right)\leftarrow\overrightarrow{X}=\overrightarrow{t}_{n},\text{body}_{n}
\]
\item If some $q\left(\underline{\;}\right)$ is not the head of any rule
in $S$, add $q\left(\overrightarrow{X}\right)\leftrightarrow\text{false}$.
\item Add Clark's Equality Theory:
\begin{enumerate}
\item $f\left(\overrightarrow{t}\right)\neq g\left(\overrightarrow{s}\right)$
for all pairs of distinct terms in the Herbrand universe of $S$.
\item $X=X,X=Y\rightarrow Y=X,X=Y\land Y=Z\rightarrow X=Z$.
\item $\overrightarrow{X}=\overrightarrow{Y}\rightarrow p\left(\overrightarrow{X}\right)=p\left(\overrightarrow{Y}\right)$
for all predicate symbols $p$ in $S$.
\item $\overrightarrow{X}\neq t\left[\overrightarrow{X}\right]$ for all
terms $t$ where $\overrightarrow{X}$ occurs.
\end{enumerate}
\end{enumerate}

\paragraph{Soundness of SLDNF}
\begin{itemize}
\item If there is a SLDNF-refutation of $P$ from $S$ with answer $\theta$
then $\text{Completion}\left(S\right)\vDash P\theta$.
\item If there is a \emph{finitely-failed} SLDNF-refutation of $P$ from
$S$ then $\text{Completion}\left(S\right)\vDash\lnot P$.
\end{itemize}

\subsubsection{Well-Founded Model Semantics}

$\left(\text{In},\text{Out}\right)$ such that:
\begin{enumerate}
\item $\text{In}\subseteq HB$.
\item $\text{Out}\subseteq HB^{\text{not}}=\left\{ \text{not }a\mid a\in HB\right\} $
\end{enumerate}
\rule[0.5ex]{0.25\columnwidth}{0.5pt}
\begin{itemize}
\item Atoms in $HB-\left(\text{In}\cup\left\{ a\mid\text{not }a\in\text{Out}\right\} \right)$
are `undecided'.
\item For $S=\left\{ p\leftarrow\text{not }p\right\} $, the well-founded
model is $\left(\{\},\{\}\right)$ so $p$ is undecided.
\end{itemize}

\subsubsection{Stable Model Semantics}

Given a normal logic program $S$ and $X\subseteq HB$, the reduce
of $S$ by $X$, $S^{X}$ is obtained by:
\begin{enumerate}
\item Eliminate all rules with $\text{not }p$ in the body, for every $p\in X$.
\item Eliminate all negative literals from the body of all remaining rules.
\end{enumerate}
$X\subseteq HB$ is a \emph{stable model} of $S$ iff the least Herbrand
model of $S^{X}$ is $X$. 
\begin{itemize}
\item \emph{Credulous reasoning}: whatever holds in some stable model.
\item \emph{Sceptical reasoning}: whatever holds in all stable models.
\end{itemize}

\section{Applications of KRR}

\begin{figure}[H]
\centering{}\includegraphics[width=0.75\columnwidth]{img/krr-applications}
\end{figure}

\paragraph{Ontologies}

Explicit, formal specification of a conceptualisation.
\begin{itemize}
\item \emph{Concepts of the domain} e.g. classes such as professors, students,
courses.
\item \emph{Relationships between these terms} e.g. all professors are staff
members.
\end{itemize}
Allow for a shared understanding of a domain (\emph{semantic interoperability}).

\paragraph{Resource Description Framework (RDF)}

Statements of the form object-attribute-value which assert properties
of objects.
\begin{itemize}
\item \emph{Triples}: (a, P, b) e.g. (introAI, isTaughtBy, ft).
\item \emph{Classes}: type(a, C).
\item \emph{Class hierarchies}: subClassOf(C, D).
\item \emph{Property hierarchies}: subPropertyOf(P, Q).
\end{itemize}

\section{Intelligent Agents and Problem Solving}

\paragraph{Intelligent Agent}

An agent that enacts on its environment, based on \emph{observations},
\emph{prior knowledge}, \emph{goals/preferences}, its \emph{abilities}
and sometimes \emph{past experience}.

\begin{figure}[H]
\centering{}\includegraphics[width=0.6\columnwidth]{img/representation}
\end{figure}

\paragraph{Representation / Knowledge Schema}

Form of knowledge used in an agent.

\paragraph{Representation}

Internal representation / formalisation of knowledge. Should be:
\begin{itemize}
\item \emph{Rich enough to express knowledge} needed to solve the problem.
\item \emph{Close to the problem}: declarative, compact and easy to maintain.
\item \emph{Amenable to efficient computation}: able to trade of accuracy
and computation time.
\item \emph{Learnable}: can be automatically acquired from people, past
experience, data.
\end{itemize}

\paragraph{Knowledge Base}

Representation of all the knowledge that is stored in an agent.

\paragraph{Solutions}
\begin{itemize}
\item \emph{Optimal}: best solutions according to some criteria.
\item \emph{Satisficing}: good enough according to some notion of an adequate
solution.
\item \emph{Approximately optimal}: close enough to the optimal solution.
\item \emph{Probable}: likely to be a solution.
\end{itemize}

\paragraph{From Problem to Representation}
\begin{itemize}
\item What level of abstraction?
\begin{itemize}
\item High-level description is harder for a machine to comprehend. May
abstract away important details.
\item Low-level description can be more accurate and predictive. But more
difficult to reason with \textemdash{} more steps / actions to choose
from.
\item Multiple levels of abstraction can solve these problems.
\end{itemize}
\end{itemize}

\paragraph{Reasoning}

Process made by a computational agent when searching for ways to determine
how to complete its task.
\begin{itemize}
\item \emph{Offline}: background knowledge needed to solve task is precomputed.
\item \emph{Online}: agents sense the environment to collect and use this
data along with background knowledge, to decide at execution time
what action to take.
\end{itemize}

\paragraph{Key Decisions}
\begin{enumerate}
\item \emph{Model of the environment}: can be expressed in terms of states
/ features / individuals and relationships between them.
\item \emph{Uncertainty}: on state (partially observable state) / effects
of actions.
\item \emph{Preferences}: trade-off between desirability of various outcomes.
\item \emph{Number of agents}: may be adversarial / cooperative.
\end{enumerate}

\end{document}
